INFO - hyperopt - Running command 'main'
INFO - hyperopt - Started run with ID "51"
using LBP
[8. 8. 0. 8. 8. 6. 5. 8. 8. 3. 5. 8. 8. 7. 8. 8. 0. 8. 7. 6. 5. 0. 7. 0.
 5. 8. 0. 0. 7. 8. 0. 5. 0. 8. 7. 0. 7. 5. 7. 8. 6. 4. 0. 5. 8. 0. 0. 0.
 8. 7. 8. 0. 8. 0. 8. 5. 6. 7. 8. 4. 7. 7. 0. 7. 6. 0. 7. 8. 5. 8. 8. 5.
 0. 5. 0. 8. 5. 7. 8. 7. 5. 5. 7. 8. 8. 0. 0. 0. 0. 6. 8. 8. 0. 5. 0. 7.
 0. 0. 8. 7. 8. 7. 8. 8. 0. 5. 5. 8. 7. 8. 7. 0. 0. 7. 7. 0. 8. 8. 0. 0.
 8. 8. 8. 5. 8. 7. 0. 0. 8. 5. 8. 0. 8. 0. 8. 8. 0. 8. 7. 0. 5. 0. 8. 7.
 0. 7. 6. 0. 8. 8. 7. 0. 0. 5. 8. 7. 8. 8. 0. 0. 5. 8. 0. 5. 7. 8. 8. 0.
 8. 7. 4. 7. 7. 0. 6. 8. 8. 8. 8. 7. 8. 5. 8. 8. 8. 8. 5. 8. 6. 5. 0. 8.
 8. 6. 8. 8. 0. 0. 8. 8. 0. 8. 0. 8. 0. 5. 0. 8. 7. 0. 0. 4. 8. 8. 4. 8.
 7. 4. 0. 5. 8. 7. 4. 8. 0. 6. 7. 8. 8. 8. 8. 7. 5. 6. 8. 0. 8. 8. 7. 7.
 8. 8. 8. 0. 8. 5. 8. 0. 6. 6. 0. 6. 4. 0. 7. 8. 8. 0. 8. 8. 7. 8. 8. 6.
 0. 8. 8. 0. 0. 0. 0. 8. 8. 0. 8. 7. 8. 8. 0. 6. 0. 7. 8. 0. 7. 8. 5. 6.
 0. 8. 7. 0. 8. 7. 8. 7. 6. 8. 8. 8. 7. 0. 0. 3. 8. 0. 0. 7. 6. 0. 6. 8.
 8. 0. 8. 0. 8. 8. 8. 8. 8. 0. 8. 0. 0. 6. 0. 0. 0. 0. 0. 6. 8. 8. 0. 0.
 5. 7. 0. 8. 8. 8. 7. 8. 8. 5. 0. 8. 0. 8. 0. 7. 0. 0. 7. 5. 8. 8. 5. 7.
 5. 7. 6. 0. 8. 0. 7. 6. 6. 7. 0. 6. 7. 8. 0. 8. 0. 0. 8. 7. 8. 8. 6. 6.
 8. 7. 0. 7. 8. 8. 5. 8. 6. 8. 7. 5. 7. 5. 7. 8. 0. 8. 7. 7. 7. 7. 8. 6.
 0. 5. 6. 8. 8. 6. 0. 0. 8. 5. 0. 8. 8. 7. 8. 8. 5. 6. 5. 8. 8. 7. 8. 8.
 7. 8. 7. 7. 8. 0. 6. 7. 0. 6. 8. 8. 5. 8. 0. 7. 7. 0. 6. 8. 7. 8. 8. 8.
 8. 0. 8. 7. 6. 8. 8. 5. 8. 0. 8. 7. 8. 7. 0. 0. 7. 6. 8. 0. 0. 8. 0. 7.
 0. 7. 8. 0. 7. 5. 0. 0. 7. 0. 7. 0. 0. 8. 8. 7. 8. 8. 8. 7. 8. 3. 8. 8.
 3. 5. 8. 7. 6. 0. 7. 8. 5. 7. 0. 0. 8. 0. 8. 7. 8. 7. 8. 7. 5. 7. 0. 8.
 8. 7. 7. 8. 0. 5. 8. 7. 8. 5. 7. 8. 5. 8. 8. 6. 0. 0. 0. 8. 5. 7. 8. 8.
 8. 5. 0. 0. 8. 8. 0. 7. 8. 6. 0. 0. 7. 8. 0. 5. 0. 7. 8. 0. 0. 0. 5. 0.
 0. 6. 0. 8. 5. 6. 8. 5. 8. 0. 8. 0. 7. 6. 0. 0. 8. 5. 0. 5. 8. 0. 8. 0.
 0. 8. 8. 8. 7. 0. 0. 8. 8. 6. 8. 0. 0. 0. 8. 0. 7. 8. 0. 7. 6. 8. 6. 0.
 7. 7. 5. 8. 6. 8. 0. 7. 0. 8. 0. 5. 5. 7. 7. 0. 6. 7. 4. 7. 8. 4. 8. 7.
 8. 6. 0. 7. 8. 8. 6. 0. 0. 6. 7. 4. 0. 2. 0. 0. 8. 0. 8. 7. 8. 8. 0. 5.
 8. 0. 7. 0. 7. 5. 0. 7. 8. 8. 5. 5. 0. 8. 8. 7. 6. 7. 8. 8. 8. 0. 0. 0.
 7. 0. 8. 8. 0. 8. 6. 8. 8. 8. 0. 8. 7. 7. 0. 0. 0. 6. 5. 0. 8. 8. 6. 7.
 8. 8. 0. 7. 0. 8. 0. 7. 0. 8. 0. 0. 8. 7. 0. 8. 0. 7. 8. 5. 8. 3. 7. 5.
 0. 0. 8. 5. 0. 3. 8. 0. 8. 7. 0. 8. 7. 8. 5. 7. 0. 8. 7. 8. 8. 0. 0. 0.
 8. 5. 7. 0. 8. 5. 7. 8. 5. 7. 5. 0. 0. 0. 8. 7. 0. 7. 8. 7. 5. 7. 5. 8.
 0. 0. 5. 6. 7. 8. 5. 5. 0. 8. 0. 8. 5. 5. 7. 7. 8. 8. 0. 8. 5. 0. 6. 8.
 7. 7. 8. 8. 7. 6. 7. 7. 6. 8. 3. 7. 8. 7. 5. 0. 5. 8. 7. 0. 5. 6. 8. 0.
 6. 5. 0. 0. 4. 7. 7. 8. 8. 6. 8. 7. 5. 8. 6. 0. 0. 0. 2. 8. 8. 8. 8. 8.
 8. 0. 8. 0. 0. 8. 7. 8. 7. 8. 6. 5. 8. 8. 8. 8. 0. 7. 8. 7. 0. 0. 8. 0.
 5. 8. 0. 8. 0. 8. 8. 8. 8. 8. 8. 0. 8. 0. 0. 7. 8. 0. 8. 7. 0. 0. 6. 7.
 0. 8. 7. 8. 0. 8. 8. 5. 7. 8. 7. 6. 0. 7. 0. 6.]
num_features: 359
data_train_padded.shape: (928, 784)
data_train.shape: (394, 28, 28, 1), data_val.shape: (70, 28, 28, 1), data_test.shape: (464, 28, 28, 1)
Initializing global variables...
2024-06-19 16:57:24.100539: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled
Variables initialized.

**********Starting job hyperopt_100_8-8_2024-06-19_0571c********* 

  0%|          | 0/355 [00:00<?, ?it/s]Number of batches: 1


Autoencoder Pretraining...

Starting epoch 1/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 561.579345703125
Running validation...
Epoch 1, Step 0: Train Loss = 550.2536010742188, Test Loss = 550.2278442382812
  0%|          | 1/355 [00:00<02:41,  2.19it/s, epoch=0, test_loss=550, train_loss=550]Starting epoch 2/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 550.1931762695312
Running validation...
Epoch 2, Step 0: Train Loss = 543.4736938476562, Test Loss = 543.5300903320312
  1%|          | 2/355 [00:00<01:34,  3.75it/s, epoch=1, test_loss=544, train_loss=543]Starting epoch 3/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 543.4403686523438
Running validation...
Epoch 3, Step 0: Train Loss = 532.8715209960938, Test Loss = 532.958984375
  1%|          | 3/355 [00:00<01:11,  4.93it/s, epoch=2, test_loss=533, train_loss=533]Starting epoch 4/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 532.9171752929688
Running validation...
Epoch 4, Step 0: Train Loss = 513.0218505859375, Test Loss = 513.0634765625
  1%|          | 4/355 [00:00<01:03,  5.55it/s, epoch=3, test_loss=513, train_loss=513]Starting epoch 5/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 513.1050415039062
Running validation...
Epoch 5, Step 0: Train Loss = 472.6399230957031, Test Loss = 472.6381530761719
  1%|▏         | 5/355 [00:00<00:56,  6.17it/s, epoch=4, test_loss=473, train_loss=473]Starting epoch 6/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 473.2953186035156
Running validation...
Epoch 6, Step 0: Train Loss = 396.9476013183594, Test Loss = 398.37884521484375
  2%|▏         | 6/355 [00:01<00:53,  6.49it/s, epoch=5, test_loss=398, train_loss=397]Starting epoch 7/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 399.15576171875
Running validation...
Epoch 7, Step 0: Train Loss = 362.48681640625, Test Loss = 368.3448181152344
  2%|▏         | 7/355 [00:01<00:51,  6.70it/s, epoch=6, test_loss=368, train_loss=362]Starting epoch 8/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 360.64215087890625
Running validation...
Epoch 8, Step 0: Train Loss = 266.8897399902344, Test Loss = 270.5570068359375
  2%|▏         | 8/355 [00:01<00:50,  6.86it/s, epoch=7, test_loss=271, train_loss=267]Starting epoch 9/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 267.1936950683594
Running validation...
Epoch 9, Step 0: Train Loss = 214.48568725585938, Test Loss = 216.8792724609375
  3%|▎         | 9/355 [00:01<00:49,  7.03it/s, epoch=8, test_loss=217, train_loss=214]Starting epoch 10/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 213.77210998535156
Running validation...
Epoch 10, Step 0: Train Loss = 188.50059509277344, Test Loss = 191.00486755371094
  3%|▎         | 10/355 [00:01<00:49,  6.98it/s, epoch=9, test_loss=191, train_loss=189]Starting epoch 11/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 188.3978729248047
Running validation...
Epoch 11, Step 0: Train Loss = 170.78671264648438, Test Loss = 174.36778259277344
  3%|▎         | 11/355 [00:01<00:48,  7.15it/s, epoch=10, test_loss=174, train_loss=171]Starting epoch 12/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 171.36483764648438
Running validation...
Epoch 12, Step 0: Train Loss = 163.34341430664062, Test Loss = 166.5401611328125
  3%|▎         | 12/355 [00:01<00:48,  7.13it/s, epoch=11, test_loss=167, train_loss=163]Starting epoch 13/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 162.7453155517578
Running validation...
Epoch 13, Step 0: Train Loss = 159.93592834472656, Test Loss = 164.05987548828125
  4%|▎         | 13/355 [00:02<00:46,  7.30it/s, epoch=12, test_loss=164, train_loss=160]Starting epoch 14/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 159.79815673828125
Running validation...
Epoch 14, Step 0: Train Loss = 158.8385772705078, Test Loss = 161.5028839111328
  4%|▍         | 14/355 [00:02<00:47,  7.25it/s, epoch=13, test_loss=162, train_loss=159]Starting epoch 15/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 157.15121459960938
Running validation...
Epoch 15, Step 0: Train Loss = 156.3875732421875, Test Loss = 162.49485778808594
  4%|▍         | 15/355 [00:02<00:45,  7.40it/s, epoch=14, test_loss=162, train_loss=156]

SOM initialization...

 10%|▉         | 34/355 [00:03<00:25, 12.72it/s, epoch=3, test_loss=1.38, train_loss=1.41]

Training...

 12%|█▏        | 44/355 [00:08<02:34,  2.01it/s, cah=[4.200668], cr_ratio=17.5, cs_ratio=1.07, epoch=8, ssom=[4.197673], test_loss=158, train_loss=155, vae=[146.37672], vc_ratio=34]         BP
INFO:tensorflow:Restoring parameters from ../models/hyperopt_100_8-8_2024-06-19_0571c/hyperopt_100_8-8_2024-06-19_0571c.ckpt
INFO - tensorflow - Restoring parameters from ../models/hyperopt_100_8-8_2024-06-19_0571c/hyperopt_100_8-8_2024-06-19_0571c.ckpt
Evaluation...
 94%|█████████▍| 335/355 [03:33<00:12,  1.57it/s, cah=[1.9127678], cr_ratio=19.5, cs_ratio=0.556, epoch=299, ssom=[4.1716375], test_loss=135, train_loss=128, vae=[121.80629], vc_ratio=56]

 NMI: 0.1704182989295242, AMI: -0.010286695553730518, PUR: 0.47333333333333333.  Name: %r.


 Time: 214.84307885169983
INFO - hyperopt - Result: {'NMI': 0.1704182989295242, 'Purity': 0.47333333333333333, 'AMI': -0.010286695553730518}
INFO - hyperopt - Completed after 0:03:35
