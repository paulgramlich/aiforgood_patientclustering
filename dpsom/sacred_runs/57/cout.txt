INFO - hyperopt - Running command 'main'
INFO - hyperopt - Started run with ID "57"
using LBP
num_features: 358
data_train_padded.shape: (928, 784)
data_train.shape: (394, 28, 28, 1), data_val.shape: (70, 28, 28, 1), data_test.shape: (464, 28, 28, 1)
Initializing global variables...
2024-06-26 14:51:06.785169: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled
Variables initialized.

**********Starting job hyperopt_100_8-8_2024-06-26_62d75********* 

  0%|          | 0/155 [00:00<?, ?it/s]Number of batches: 1


Autoencoder Pretraining...

Starting epoch 1/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 561.5324096679688
Running validation...
Epoch 1, Step 0: Train Loss = 1725.588623046875, Test Loss = 1772.6121826171875
  1%|          | 1/155 [00:00<01:26,  1.77it/s, epoch=0, test_loss=1.77e+3, train_loss=1.73e+3]Starting epoch 2/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 1730.322021484375
Running validation...
Epoch 2, Step 0: Train Loss = 71914.5234375, Test Loss = 74678.109375
  1%|▏         | 2/155 [00:00<00:48,  3.18it/s, epoch=1, test_loss=7.47e+4, train_loss=7.19e+4]Starting epoch 3/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 71960.1796875
Running validation...
Epoch 3, Step 0: Train Loss = 898980.875, Test Loss = 933940.375
  2%|▏         | 3/155 [00:00<00:35,  4.29it/s, epoch=2, test_loss=9.34e+5, train_loss=8.99e+5]Starting epoch 4/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 901347.125
Running validation...
Epoch 4, Step 0: Train Loss = 13747.810546875, Test Loss = 13697.94140625
  3%|▎         | 4/155 [00:00<00:29,  5.17it/s, epoch=3, test_loss=1.37e+4, train_loss=1.37e+4]Starting epoch 5/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 13479.6328125
Running validation...
Epoch 5, Step 0: Train Loss = 17740.599609375, Test Loss = 18458.3828125
  3%|▎         | 5/155 [00:01<00:26,  5.77it/s, epoch=4, test_loss=1.85e+4, train_loss=17740.6]Starting epoch 6/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 17685.51171875
Running validation...
Epoch 6, Step 0: Train Loss = 152182.015625, Test Loss = 159484.140625
  4%|▍         | 6/155 [00:01<00:23,  6.25it/s, epoch=5, test_loss=1.59e+5, train_loss=1.52e+5]Starting epoch 7/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 151979.84375
Running validation...
Epoch 7, Step 0: Train Loss = 153173.5, Test Loss = 158079.078125
  5%|▍         | 7/155 [00:01<00:22,  6.69it/s, epoch=6, test_loss=1.58e+5, train_loss=1.53e+5]Starting epoch 8/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 150835.890625
Running validation...
Epoch 8, Step 0: Train Loss = 19759.419921875, Test Loss = 20134.48046875
  5%|▌         | 8/155 [00:01<00:21,  6.90it/s, epoch=7, test_loss=2.01e+4, train_loss=1.98e+4]Starting epoch 9/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 19343.69140625
Running validation...
Epoch 9, Step 0: Train Loss = 61780.70703125, Test Loss = 63806.92578125
  6%|▌         | 9/155 [00:01<00:20,  6.98it/s, epoch=8, test_loss=6.38e+4, train_loss=6.18e+4]Starting epoch 10/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 61824.33984375
Running validation...
Epoch 10, Step 0: Train Loss = 29136.99609375, Test Loss = 28826.95703125
  6%|▋         | 10/155 [00:01<00:20,  7.02it/s, epoch=9, test_loss=2.88e+4, train_loss=2.91e+4]Starting epoch 11/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 28632.06640625
Running validation...
Epoch 11, Step 0: Train Loss = 29451.9296875, Test Loss = 31468.8671875
  7%|▋         | 11/155 [00:01<00:19,  7.23it/s, epoch=10, test_loss=3.15e+4, train_loss=2.95e+4]Starting epoch 12/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 30642.001953125
Running validation...
Epoch 12, Step 0: Train Loss = 16408.658203125, Test Loss = 16231.462890625
  8%|▊         | 12/155 [00:02<00:19,  7.21it/s, epoch=11, test_loss=1.62e+4, train_loss=1.64e+4]Starting epoch 13/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 15846.6669921875
Running validation...
Epoch 13, Step 0: Train Loss = 26234.51953125, Test Loss = 27341.5390625
  8%|▊         | 13/155 [00:02<00:19,  7.29it/s, epoch=12, test_loss=2.73e+4, train_loss=2.62e+4]Starting epoch 14/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 26307.501953125
Running validation...
Epoch 14, Step 0: Train Loss = 36782.21875, Test Loss = 38545.203125
  9%|▉         | 14/155 [00:02<00:19,  7.35it/s, epoch=13, test_loss=3.85e+4, train_loss=3.68e+4]Starting epoch 15/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 36636.21875
Running validation...
Epoch 15, Step 0: Train Loss = 10490.66796875, Test Loss = 9887.8271484375
 10%|▉         | 15/155 [00:02<00:19,  7.34it/s, epoch=14, test_loss=9.89e+3, train_loss=1.05e+4]

SOM initialization...

 22%|██▏       | 34/155 [00:03<00:08, 13.58it/s, epoch=3, test_loss=278, train_loss=273]         

Training...

 23%|██▎       | 36/155 [00:04<00:19,  6.15it/s, cah=[-1.04116815e-07], cr_ratio=8.51e+3, cs_ratio=-2.5e-8, epoch=0, ssom=[4.158882], test_loss=3.66e+4, train_loss=3.5e+4, vae=[35380.02], vc_ratio=-3.4e+11]/Users/paulgramlich/Developer/git/aiforgood_patientclustering/dpsom/dpsom/DPSOM.py:411: RuntimeWarning: divide by zero encountered in scalar divide
  vae_cah_ratio=elbo_loss[0]/cah_loss[0]
 28%|██▊       | 44/155 [00:08<00:52,  2.11it/s, cah=[-1.9936506e-07], cr_ratio=4.63e+3, cs_ratio=-1.74e-10, epoch=8, ssom=[4.158882], test_loss=1.27e+4, train_loss=1.27e+4, vae=[12358.605], vc_ratio=inf]  
INFO:tensorflow:Restoring parameters from ../models/hyperopt_100_8-8_2024-06-26_62d75/hyperopt_100_8-8_2024-06-26_62d75.ckpt
INFO - tensorflow - Restoring parameters from ../models/hyperopt_100_8-8_2024-06-26_62d75/hyperopt_100_8-8_2024-06-26_62d75.ckpt
Evaluation...
 87%|████████▋ | 135/155 [01:02<00:09,  2.15it/s, cah=[2.1007863e-06], cr_ratio=694, cs_ratio=2.33e-7, epoch=99, ssom=[4.158882], test_loss=165, train_loss=154, vae=[149.81532], vc_ratio=inf]
INFO - hyperopt - Result: {'NMI': 0.0389357676241294, 'Purity': 0.37, 'AMI': -0.00870877280357977, 'Silhouette Score': -0.1747741665320514, 'Calinski-Harabasz Index': 1.3908111479617928, 'Davies-Bouldin Index': 5.38938699932863}

 NMI: 0.0389357676241294, AMI: -0.00870877280357977, PUR: 0.37.  Name: %r.


 Time: 63.58276104927063
INFO - hyperopt - Completed after 0:01:04
