INFO - hyperopt - Running command 'main'
INFO - hyperopt - Started run with ID "70"
using LBP
num_features: 358
data_train_padded.shape: (928, 784)
data_train.shape: (461, 28, 28, 1), data_val.shape: (95, 28, 28, 1), data_test.shape: (372, 28, 28, 1)
Initializing global variables...
2024-07-12 18:55:14.366046: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled
Variables initialized.

**********Starting job hyperopt_100_3-3_2024-07-12_0b122********* 

  0%|          | 0/735 [00:00<?, ?it/s]Number of batches: 7


Autoencoder Pretraining...

Starting epoch 1/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 561.6319580078125
Running validation...
Epoch 1, Step 0: Train Loss = 957.870849609375, Test Loss = 867.9942626953125
  0%|          | 1/735 [00:00<04:03,  3.01it/s, epoch=0, test_loss=868, train_loss=958]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 1036.460693359375
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 18608.556640625
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 874432.5
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 51937.5703125
  1%|          | 5/735 [00:00<00:53, 13.53it/s, epoch=0, test_loss=868, train_loss=5.19e+4]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 41009.0234375
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 137565.125
Starting epoch 2/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 39163.72265625
Running validation...
Epoch 2, Step 0: Train Loss = 141080.328125, Test Loss = 126937.09375
  1%|          | 8/735 [00:00<00:40, 17.90it/s, epoch=1, test_loss=1.27e+5, train_loss=1.41e+5]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 170200.375
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 412919.5625
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 17173.6953125
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 43465.1640625
  2%|▏         | 12/735 [00:00<00:30, 23.46it/s, epoch=1, test_loss=1.27e+5, train_loss=4.35e+4]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 24633.1796875
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 22954.14453125
Starting epoch 3/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 33998.9765625
Running validation...
Epoch 3, Step 0: Train Loss = 39515.2578125, Test Loss = 33735.38671875
  2%|▏         | 15/735 [00:00<00:29, 24.57it/s, epoch=2, test_loss=3.37e+4, train_loss=3.95e+4]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 40217.53515625
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 34985.4375
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 29882.53125
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 24875.609375
  3%|▎         | 19/735 [00:00<00:25, 28.08it/s, epoch=2, test_loss=3.37e+4, train_loss=2.49e+4]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 38009.73046875
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 14377.56640625
Starting epoch 4/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 13895.78125
Running validation...
Epoch 4, Step 0: Train Loss = 14530.59765625, Test Loss = 18185.78125
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 18813.330078125
  3%|▎         | 23/735 [00:01<00:24, 28.51it/s, epoch=3, test_loss=1.82e+4, train_loss=1.88e+4]Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 8734.166015625
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 12788.1181640625
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 22911.06640625
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 17246.189453125
  4%|▎         | 27/735 [00:01<00:23, 30.41it/s, epoch=3, test_loss=1.82e+4, train_loss=1.72e+4]Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 12239.9970703125
Starting epoch 5/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 10566.404296875
Running validation...
Epoch 5, Step 0: Train Loss = 7907.4150390625, Test Loss = 8600.4296875
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 9141.3603515625
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 6625.15234375
  4%|▍         | 31/735 [00:01<00:23, 30.11it/s, epoch=4, test_loss=8.6e+3, train_loss=6.63e+3] Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 8559.607421875
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 7116.724609375
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 3615.514404296875
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 2749.859619140625
  5%|▍         | 35/735 [00:01<00:22, 30.84it/s, epoch=4, test_loss=8.6e+3, train_loss=2.75e+3]Starting epoch 6/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 3199.793212890625
Running validation...
Epoch 6, Step 0: Train Loss = 3458.01806640625, Test Loss = 3383.998779296875
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 3903.48681640625
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 2699.468505859375
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 3135.70654296875
  5%|▌         | 39/735 [00:01<00:22, 30.29it/s, epoch=5, test_loss=3.38e+3, train_loss=3.14e+3]Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 7610.0732421875
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 14804.2685546875
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 9791.3818359375
Starting epoch 7/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 14524.4560546875
Running validation...
Epoch 7, Step 0: Train Loss = 5786.82421875, Test Loss = 5910.259765625
  6%|▌         | 43/735 [00:01<00:24, 28.75it/s, epoch=6, test_loss=5910.26, train_loss=5.79e+3]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 6784.65869140625
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 4347.369140625
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 8767.576171875
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 6088.0537109375
  6%|▋         | 47/735 [00:01<00:22, 30.63it/s, epoch=6, test_loss=5910.26, train_loss=6.09e+3]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 6139.8876953125
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 3893.9013671875
Starting epoch 8/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 2611.8935546875
Running validation...
Epoch 8, Step 0: Train Loss = 3027.62255859375, Test Loss = 3190.9208984375
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 3302.165771484375
  7%|▋         | 51/735 [00:01<00:22, 30.52it/s, epoch=7, test_loss=3.19e+3, train_loss=3.3e+3] Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 3741.779541015625
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 4668.8203125
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 2893.2861328125
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 1765.758056640625
  7%|▋         | 55/735 [00:02<00:21, 31.71it/s, epoch=7, test_loss=3.19e+3, train_loss=1.77e+3]Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 1521.8609619140625
Starting epoch 9/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 2393.46923828125
Running validation...
Epoch 9, Step 0: Train Loss = 2682.78125, Test Loss = 2513.75048828125
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 2967.091064453125
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 1587.44287109375
  8%|▊         | 59/735 [00:02<00:21, 30.78it/s, epoch=8, test_loss=2.51e+3, train_loss=1.59e+3]Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 1569.7801513671875
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 1109.7998046875
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 919.357177734375
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 769.7280883789062
  9%|▊         | 63/735 [00:02<00:21, 31.58it/s, epoch=8, test_loss=2.51e+3, train_loss=770]    Starting epoch 10/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 861.6954345703125
Running validation...
Epoch 10, Step 0: Train Loss = 814.7595825195312, Test Loss = 922.662109375
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 885.9025268554688
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 812.6962890625
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 958.45458984375
  9%|▉         | 67/735 [00:02<00:20, 31.83it/s, epoch=9, test_loss=923, train_loss=958]    Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 722.4053955078125
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 711.312255859375
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 642.52197265625
Starting epoch 11/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 503.3701171875
Running validation...
Epoch 11, Step 0: Train Loss = 523.5217895507812, Test Loss = 512.7452392578125
 10%|▉         | 71/735 [00:02<00:21, 31.07it/s, epoch=10, test_loss=513, train_loss=524]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 617.6742553710938
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 593.724609375
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 717.7527465820312
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 728.1564331054688
 10%|█         | 75/735 [00:02<00:20, 32.34it/s, epoch=10, test_loss=513, train_loss=728]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 676.204345703125
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 510.7438049316406
Starting epoch 12/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 528.238037109375
Running validation...
Epoch 12, Step 0: Train Loss = 472.7158203125, Test Loss = 464.2987060546875
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 546.2381591796875
 11%|█         | 79/735 [00:02<00:20, 31.58it/s, epoch=11, test_loss=464, train_loss=546]Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 490.0852966308594
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 760.488525390625
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 613.2752075195312
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 402.9208068847656
 11%|█▏        | 83/735 [00:02<00:20, 32.54it/s, epoch=11, test_loss=464, train_loss=403]Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 412.4459228515625
Starting epoch 13/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 505.57965087890625
Running validation...
Epoch 13, Step 0: Train Loss = 406.9136047363281, Test Loss = 418.833740234375
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 453.65582275390625
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 349.82861328125
 12%|█▏        | 87/735 [00:03<00:20, 32.09it/s, epoch=12, test_loss=419, train_loss=350]Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 517.5322265625
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 433.3011474609375
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 322.4516296386719
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 260.3541259765625
 12%|█▏        | 91/735 [00:03<00:19, 32.40it/s, epoch=12, test_loss=419, train_loss=260]Starting epoch 14/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 291.1496276855469
Running validation...
Epoch 14, Step 0: Train Loss = 306.34259033203125, Test Loss = 311.90106201171875
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 331.32177734375
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 284.6890563964844
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 299.5924072265625
 13%|█▎        | 95/735 [00:03<00:20, 31.83it/s, epoch=13, test_loss=312, train_loss=300]Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 270.5960998535156
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 245.20904541015625
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 209.05943298339844
Starting epoch 15/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 222.38479614257812
Running validation...
Epoch 15, Step 0: Train Loss = 222.34268188476562, Test Loss = 247.1464385986328
 13%|█▎        | 99/735 [00:03<00:22, 28.54it/s, epoch=14, test_loss=247, train_loss=222]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 239.29714965820312
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 207.27163696289062
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 243.564697265625
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 243.76290893554688
Batch 6/7
 14%|█▍        | 103/735 [00:03<00:21, 28.92it/s, epoch=14, test_loss=247, train_loss=244]Batch data shape: (64, 28, 28, 1)
Train Loss: 217.41033935546875
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 212.58041381835938


SOM initialization...

 32%|███▏      | 232/735 [00:04<00:04, 119.81it/s, epoch=3, test_loss=7.08, train_loss=6.34]

Training...

 40%|███▉      | 292/735 [00:09<00:32, 13.63it/s, cah=[1.639899], cr_ratio=41.3, cs_ratio=0.997, epoch=6, ssom=[2.2085116], test_loss=172, train_loss=169, vae=[164.64703], vc_ratio=86.7]8]4e+3]P
INFO:tensorflow:Restoring parameters from ../models/hyperopt_100_3-3_2024-07-12_0b122/hyperopt_100_3-3_2024-07-12_0b122.ckpt
INFO - tensorflow - Restoring parameters from ../models/hyperopt_100_3-3_2024-07-12_0b122/hyperopt_100_3-3_2024-07-12_0b122.ckpt
Evaluation...
 81%|████████  | 595/735 [00:36<00:08, 16.13it/s, cah=[0.006495304], cr_ratio=57.2, cs_ratio=0.215, epoch=49, ssom=[2.197269], test_loss=143, train_loss=138, vae=[135.5466], vc_ratio=3.41e+3]

 NMI: 0.05054773843165654, AMI: 0.003212160735005214, PUR: 0.365625.  Name: %r.


 Time: 37.72486186027527
INFO - hyperopt - Result: {'NMI': 0.05054773843165654, 'Purity': 0.365625, 'AMI': 0.003212160735005214, 'Silhouette Score': -0.0663873410188742, 'Calinski-Harabasz Index': 1.7912783844332831, 'Davies-Bouldin Index': 8.411161119838365}
INFO - hyperopt - Completed after 0:00:38
