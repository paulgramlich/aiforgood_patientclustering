INFO - hyperopt - Running command 'main'
INFO - hyperopt - Started run with ID "68"
using LBP
num_features: 358
data_train_padded.shape: (928, 784)
data_train.shape: (461, 28, 28, 1), data_val.shape: (95, 28, 28, 1), data_test.shape: (372, 28, 28, 1)
Initializing global variables...
2024-07-12 18:52:12.431641: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled
Variables initialized.

**********Starting job hyperopt_100_3-3_2024-07-12_19b6b********* 

  0%|          | 0/735 [00:00<?, ?it/s]Number of batches: 7


Autoencoder Pretraining...

Starting epoch 1/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 561.6319580078125
Running validation...
Epoch 1, Step 0: Train Loss = 558.6043090820312, Test Loss = 558.5692749023438
  0%|          | 1/735 [00:00<04:09,  2.94it/s, epoch=0, test_loss=559, train_loss=559]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 558.7147827148438
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 556.5796508789062
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 554.99755859375
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 553.5084228515625
  1%|          | 5/735 [00:00<00:54, 13.48it/s, epoch=0, test_loss=559, train_loss=554]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 552.4434204101562
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 551.436767578125
Starting epoch 2/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 550.5556030273438
Running validation...
Epoch 2, Step 0: Train Loss = 549.638427734375, Test Loss = 549.7811889648438
  1%|          | 8/735 [00:00<00:41, 17.54it/s, epoch=1, test_loss=550, train_loss=550]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 549.6957397460938
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 548.952880859375
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 548.01171875
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 547.4108276367188
  2%|▏         | 12/735 [00:00<00:31, 23.16it/s, epoch=1, test_loss=550, train_loss=547]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 546.4591064453125
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 545.7696533203125
Starting epoch 3/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 544.7098388671875
Running validation...
Epoch 3, Step 0: Train Loss = 543.7133178710938, Test Loss = 543.771484375
  2%|▏         | 15/735 [00:00<00:29, 24.40it/s, epoch=2, test_loss=544, train_loss=544]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 543.7530517578125
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 542.6426391601562
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 541.6019897460938
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 540.1324462890625
  3%|▎         | 19/735 [00:00<00:25, 27.94it/s, epoch=2, test_loss=544, train_loss=540]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 538.6138916015625
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 537.1739501953125
Starting epoch 4/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 535.1148681640625
Running validation...
Epoch 4, Step 0: Train Loss = 533.3278198242188, Test Loss = 533.130859375
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 533.1140747070312
  3%|▎         | 23/735 [00:01<00:25, 28.42it/s, epoch=3, test_loss=533, train_loss=533]Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 530.8805541992188
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 528.1121826171875
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 525.6488647460938
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 521.87255859375
  4%|▎         | 27/735 [00:01<00:23, 30.61it/s, epoch=3, test_loss=533, train_loss=522]Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 518.0488891601562
Starting epoch 5/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 513.331298828125
Running validation...
Epoch 5, Step 0: Train Loss = 507.9280090332031, Test Loss = 508.2323303222656
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 509.4324645996094
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 502.5718994140625
  4%|▍         | 31/735 [00:01<00:23, 30.51it/s, epoch=4, test_loss=508, train_loss=503]Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 495.73663330078125
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 488.8426208496094
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 479.70684814453125
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 465.37310791015625
  5%|▍         | 35/735 [00:01<00:22, 31.55it/s, epoch=4, test_loss=508, train_loss=465]Starting epoch 6/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 456.65850830078125
Running validation...
Epoch 6, Step 0: Train Loss = 440.2708435058594, Test Loss = 443.2133483886719
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 445.646484375
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 428.29681396484375
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 418.1651611328125
  5%|▌         | 39/735 [00:01<00:22, 31.29it/s, epoch=5, test_loss=443, train_loss=418]Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 398.2983703613281
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 381.738525390625
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 365.14349365234375
Starting epoch 7/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 358.5281982421875
Running validation...
Epoch 7, Step 0: Train Loss = 336.7022399902344, Test Loss = 336.9791564941406
  6%|▌         | 43/735 [00:01<00:23, 30.06it/s, epoch=6, test_loss=337, train_loss=337]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 353.1845703125
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 315.1763610839844
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 319.1055908203125
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 294.1308898925781
  6%|▋         | 47/735 [00:01<00:21, 31.49it/s, epoch=6, test_loss=337, train_loss=294]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 272.414306640625
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 250.93017578125
Starting epoch 8/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 245.8142547607422
Running validation...
Epoch 8, Step 0: Train Loss = 236.45547485351562, Test Loss = 240.17906188964844
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 243.08648681640625
  7%|▋         | 51/735 [00:01<00:22, 30.63it/s, epoch=7, test_loss=240, train_loss=243]Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 224.64065551757812
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 230.16732788085938
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 217.8561248779297
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 205.81935119628906
  7%|▋         | 55/735 [00:02<00:21, 31.60it/s, epoch=7, test_loss=240, train_loss=206]Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 192.50009155273438
Starting epoch 9/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 195.1486053466797
Running validation...
Epoch 9, Step 0: Train Loss = 190.5682830810547, Test Loss = 194.149658203125
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 198.05860900878906
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 180.19906616210938
  8%|▊         | 59/735 [00:02<00:21, 31.35it/s, epoch=8, test_loss=194, train_loss=180]Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 191.26536560058594
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 184.81790161132812
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 173.97482299804688
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 168.8543243408203
  9%|▊         | 63/735 [00:02<00:21, 31.57it/s, epoch=8, test_loss=194, train_loss=169]Starting epoch 10/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 172.21026611328125
Running validation...
Epoch 10, Step 0: Train Loss = 170.26931762695312, Test Loss = 176.742919921875
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 178.53089904785156
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 164.13470458984375
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 177.04319763183594
  9%|▉         | 67/735 [00:02<00:21, 31.29it/s, epoch=9, test_loss=177, train_loss=177]Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 169.91458129882812
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 161.3620147705078
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 155.85116577148438
Starting epoch 11/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 160.63990783691406
Running validation...
Epoch 11, Step 0: Train Loss = 159.7760772705078, Test Loss = 153.36215209960938
 10%|▉         | 71/735 [00:02<00:21, 30.77it/s, epoch=10, test_loss=153, train_loss=160]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 169.46051025390625
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 153.32203674316406
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 168.796142578125
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 160.8449249267578
 10%|█         | 75/735 [00:02<00:20, 31.76it/s, epoch=10, test_loss=153, train_loss=161]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 154.27626037597656
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 149.788330078125
Starting epoch 12/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 154.166259765625
Running validation...
Epoch 12, Step 0: Train Loss = 153.3175506591797, Test Loss = 152.005615234375
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 163.54408264160156
 11%|█         | 79/735 [00:02<00:20, 31.57it/s, epoch=11, test_loss=152, train_loss=164]Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 148.27491760253906
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 161.79054260253906
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 156.34584045410156
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 150.39637756347656
 11%|█▏        | 83/735 [00:02<00:20, 31.84it/s, epoch=11, test_loss=152, train_loss=150]Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 145.0921173095703
Starting epoch 13/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 150.51449584960938
Running validation...
Epoch 13, Step 0: Train Loss = 149.4897918701172, Test Loss = 151.865234375
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 159.23489379882812
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 145.43885803222656
 12%|█▏        | 87/735 [00:03<00:20, 31.77it/s, epoch=12, test_loss=152, train_loss=145]Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 158.4932098388672
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 153.73883056640625
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 147.21897888183594
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 143.14268493652344
 12%|█▏        | 91/735 [00:03<00:20, 32.11it/s, epoch=12, test_loss=152, train_loss=143]Starting epoch 14/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 147.82102966308594
Running validation...
Epoch 14, Step 0: Train Loss = 146.8101043701172, Test Loss = 150.71466064453125
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 155.87095642089844
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 143.6162109375
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 155.72203063964844
 13%|█▎        | 95/735 [00:03<00:20, 31.48it/s, epoch=13, test_loss=151, train_loss=156]Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 151.0623016357422
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 145.6627197265625
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 141.24380493164062
Starting epoch 15/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 145.6638641357422
Running validation...
Epoch 15, Step 0: Train Loss = 145.66957092285156, Test Loss = 151.5845947265625
Batch 2/7
Batch data shape: (64, 28, 28, 1)
 13%|█▎        | 99/735 [00:03<00:20, 30.43it/s, epoch=14, test_loss=152, train_loss=146]Train Loss: 154.7269744873047
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 141.84642028808594
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 153.67967224121094
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 149.79779052734375
 14%|█▍        | 103/735 [00:03<00:20, 30.37it/s, epoch=14, test_loss=152, train_loss=150]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 144.38604736328125
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 140.2137908935547


SOM initialization...

 32%|███▏      | 232/735 [00:04<00:04, 117.91it/s, epoch=3, test_loss=1.72, train_loss=1.77]

Training...

 39%|███▉      | 289/735 [00:09<00:38, 11.55it/s, cah=[0.52888244], cr_ratio=50.4, cs_ratio=0.273, epoch=6, ssom=[2.204176], test_loss=144, train_loss=143, vae=[139.49913], vc_ratio=238]  LBP
INFO:tensorflow:Restoring parameters from ../models/hyperopt_100_3-3_2024-07-12_19b6b/hyperopt_100_3-3_2024-07-12_19b6b.ckpt
INFO - tensorflow - Restoring parameters from ../models/hyperopt_100_3-3_2024-07-12_19b6b/hyperopt_100_3-3_2024-07-12_19b6b.ckpt
Evaluation...
 81%|████████  | 595/735 [00:37<00:08, 15.97it/s, cah=[0.40178174], cr_ratio=50.7, cs_ratio=0.221, epoch=49, ssom=[2.2100878], test_loss=138, train_loss=136, vae=[133.19174], vc_ratio=285]

 NMI: 0.05157284736886618, AMI: -0.005184551862430342, PUR: 0.371875.  Name: %r.


 Time: 38.10975408554077
INFO - hyperopt - Result: {'NMI': 0.05157284736886618, 'Purity': 0.371875, 'AMI': -0.005184551862430342, 'Silhouette Score': -0.14211043738280343, 'Calinski-Harabasz Index': 1.127323902030071, 'Davies-Bouldin Index': 2.9520052272699124}
INFO - hyperopt - Completed after 0:00:38
