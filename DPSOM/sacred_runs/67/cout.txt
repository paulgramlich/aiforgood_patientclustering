INFO - hyperopt - Running command 'main'
INFO - hyperopt - Started run with ID "67"
using LBP
num_features: 358
data_train_padded.shape: (928, 784)
data_train.shape: (461, 28, 28, 1), data_val.shape: (95, 28, 28, 1), data_test.shape: (372, 28, 28, 1)
Initializing global variables...
2024-07-12 18:49:22.305615: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled
Variables initialized.

**********Starting job hyperopt_100_3-3_2024-07-12_45846********* 

  0%|          | 0/945 [00:00<?, ?it/s]Number of batches: 7


Autoencoder Pretraining...

Starting epoch 1/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 561.6319580078125
Running validation...
Epoch 1, Step 0: Train Loss = 558.6043090820312, Test Loss = 558.5692749023438
  0%|          | 1/945 [00:00<05:33,  2.83it/s, epoch=0, test_loss=559, train_loss=559]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 558.7147827148438
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 556.5796508789062
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 554.99755859375
  0%|          | 4/945 [00:00<01:32, 10.15it/s, epoch=0, test_loss=559, train_loss=555]Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 553.5084228515625
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 552.4434204101562
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 551.436767578125
  1%|          | 7/945 [00:00<01:00, 15.63it/s, epoch=0, test_loss=559, train_loss=551]Starting epoch 2/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 550.5556030273438
Running validation...
Epoch 2, Step 0: Train Loss = 549.638427734375, Test Loss = 549.7811889648438
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 549.6957397460938
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 548.952880859375
  1%|          | 10/945 [00:00<00:48, 19.43it/s, epoch=1, test_loss=550, train_loss=549]Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 548.01171875
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 547.4108276367188
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 546.4591064453125
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 545.7696533203125
  1%|▏         | 14/945 [00:00<00:39, 23.45it/s, epoch=1, test_loss=550, train_loss=546]Starting epoch 3/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 544.7098388671875
Running validation...
Epoch 3, Step 0: Train Loss = 543.7133178710938, Test Loss = 543.771484375
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 543.7530517578125
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 542.6426391601562
  2%|▏         | 17/945 [00:00<00:36, 25.10it/s, epoch=2, test_loss=544, train_loss=543]Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 541.6019897460938
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 540.1324462890625
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 538.6138916015625
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 537.1739501953125
  2%|▏         | 21/945 [00:01<00:33, 27.41it/s, epoch=2, test_loss=544, train_loss=537]Starting epoch 4/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 535.1148681640625
Running validation...
Epoch 4, Step 0: Train Loss = 533.3278198242188, Test Loss = 533.130859375
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 533.1140747070312
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 530.8805541992188
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 528.1121826171875
  3%|▎         | 25/945 [00:01<00:32, 28.53it/s, epoch=3, test_loss=533, train_loss=528]Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 525.6488647460938
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 521.87255859375
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 518.0488891601562
Starting epoch 5/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 513.331298828125
Running validation...
Epoch 5, Step 0: Train Loss = 507.9280090332031, Test Loss = 508.2323303222656
  3%|▎         | 29/945 [00:01<00:31, 28.80it/s, epoch=4, test_loss=508, train_loss=508]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 509.4324645996094
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 502.5718994140625
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 495.73663330078125
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 488.8426208496094
  3%|▎         | 33/945 [00:01<00:30, 30.16it/s, epoch=4, test_loss=508, train_loss=489]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 479.70684814453125
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 465.37310791015625
Starting epoch 6/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 456.65850830078125
Running validation...
Epoch 6, Step 0: Train Loss = 440.2708435058594, Test Loss = 443.2133483886719
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 445.646484375
  4%|▍         | 37/945 [00:01<00:29, 30.38it/s, epoch=5, test_loss=443, train_loss=446]Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 428.29681396484375
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 418.1651611328125
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 398.2983703613281
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 381.738525390625
  4%|▍         | 41/945 [00:01<00:28, 31.35it/s, epoch=5, test_loss=443, train_loss=382]Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 365.14349365234375
Starting epoch 7/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 358.5281982421875
Running validation...
Epoch 7, Step 0: Train Loss = 336.7022399902344, Test Loss = 336.9791564941406
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 353.1845703125
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 315.1763610839844
  5%|▍         | 45/945 [00:01<00:28, 31.42it/s, epoch=6, test_loss=337, train_loss=315]Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 319.1055908203125
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 294.1308898925781
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 272.414306640625
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 250.93017578125
  5%|▌         | 49/945 [00:01<00:27, 32.10it/s, epoch=6, test_loss=337, train_loss=251]Starting epoch 8/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 245.8142547607422
Running validation...
Epoch 8, Step 0: Train Loss = 236.45547485351562, Test Loss = 240.17906188964844
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 243.08648681640625
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 224.64065551757812
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 230.16732788085938
  6%|▌         | 53/945 [00:02<00:28, 31.75it/s, epoch=7, test_loss=240, train_loss=230]Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 217.8561248779297
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 205.81935119628906
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 192.50009155273438
Starting epoch 9/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 195.1486053466797
Running validation...
Epoch 9, Step 0: Train Loss = 190.5682830810547, Test Loss = 194.149658203125
  6%|▌         | 57/945 [00:02<00:28, 31.39it/s, epoch=8, test_loss=194, train_loss=191]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 198.05860900878906
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 180.19906616210938
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 191.26536560058594
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 184.81790161132812
  6%|▋         | 61/945 [00:02<00:27, 32.05it/s, epoch=8, test_loss=194, train_loss=185]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 173.97482299804688
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 168.8543243408203
Starting epoch 10/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 172.21026611328125
Running validation...
Epoch 10, Step 0: Train Loss = 170.26931762695312, Test Loss = 176.742919921875
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 178.53089904785156
  7%|▋         | 65/945 [00:02<00:27, 31.71it/s, epoch=9, test_loss=177, train_loss=179]Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 164.13470458984375
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 177.04319763183594
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 169.91458129882812
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 161.3620147705078
  7%|▋         | 69/945 [00:02<00:27, 32.31it/s, epoch=9, test_loss=177, train_loss=161]Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 155.85116577148438
Starting epoch 11/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 160.63990783691406
Running validation...
Epoch 11, Step 0: Train Loss = 159.7760772705078, Test Loss = 153.36215209960938
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 169.46051025390625
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 153.32203674316406
  8%|▊         | 73/945 [00:02<00:27, 31.84it/s, epoch=10, test_loss=153, train_loss=153]Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 168.796142578125
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 160.8449249267578
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 154.27626037597656
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 149.788330078125
  8%|▊         | 77/945 [00:02<00:27, 32.02it/s, epoch=10, test_loss=153, train_loss=150]Starting epoch 12/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 154.166259765625
Running validation...
Epoch 12, Step 0: Train Loss = 153.3175506591797, Test Loss = 152.005615234375
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 163.54408264160156
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 148.27491760253906
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 161.79054260253906
  9%|▊         | 81/945 [00:02<00:27, 31.16it/s, epoch=11, test_loss=152, train_loss=162]Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 156.34584045410156
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 150.39637756347656
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 145.0921173095703
Starting epoch 13/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 150.51449584960938
Running validation...
Epoch 13, Step 0: Train Loss = 149.4897918701172, Test Loss = 151.865234375
  9%|▉         | 85/945 [00:03<00:28, 30.36it/s, epoch=12, test_loss=152, train_loss=149]Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 159.23489379882812
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 145.43885803222656
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 158.4932098388672
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 153.73883056640625
  9%|▉         | 89/945 [00:03<00:27, 31.13it/s, epoch=12, test_loss=152, train_loss=154]Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 147.21897888183594
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 143.14268493652344
Starting epoch 14/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 147.82102966308594
Running validation...
Epoch 14, Step 0: Train Loss = 146.8101043701172, Test Loss = 150.71466064453125
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 155.87095642089844
 10%|▉         | 93/945 [00:03<00:27, 31.10it/s, epoch=13, test_loss=151, train_loss=156]Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 143.6162109375
Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 155.72203063964844
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 151.0623016357422
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 145.6627197265625
 10%|█         | 97/945 [00:03<00:26, 31.86it/s, epoch=13, test_loss=151, train_loss=146]Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 141.24380493164062
Starting epoch 15/15
Batch 1/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 145.6638641357422
Running validation...
Epoch 15, Step 0: Train Loss = 145.66957092285156, Test Loss = 151.5845947265625
Batch 2/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 154.7269744873047
Batch 3/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 141.84642028808594
 11%|█         | 101/945 [00:03<00:27, 31.02it/s, epoch=14, test_loss=152, train_loss=142]Batch 4/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 153.67967224121094
Batch 5/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 149.79779052734375
Batch 6/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 144.38604736328125
Batch 7/7
Batch data shape: (64, 28, 28, 1)
Train Loss: 140.2137908935547
 11%|█         | 105/945 [00:03<00:26, 32.07it/s, epoch=14, test_loss=152, train_loss=140]

SOM initialization...

 26%|██▌       | 243/945 [00:04<00:05, 117.64it/s, epoch=4, test_loss=1.8, train_loss=1.75] 

Training...

 30%|███       | 287/945 [00:09<00:45, 14.31it/s, cah=[0.55443686], cr_ratio=50.3, cs_ratio=0.278, epoch=5, ssom=[2.2039506], test_loss=144, train_loss=143, vae=[139.96213], vc_ratio=234]] P
INFO:tensorflow:Restoring parameters from ../models/hyperopt_100_3-3_2024-07-12_45846/hyperopt_100_3-3_2024-07-12_45846.ckpt
INFO - tensorflow - Restoring parameters from ../models/hyperopt_100_3-3_2024-07-12_45846/hyperopt_100_3-3_2024-07-12_45846.ckpt
Evaluation...
 85%|████████▌ | 805/945 [01:02<00:10, 12.83it/s, cah=[0.4231813], cr_ratio=50.1, cs_ratio=0.206, epoch=79, ssom=[2.2185068], test_loss=131, train_loss=128, vae=[124.71709], vc_ratio=299]

 NMI: 0.03460001109980916, AMI: -0.014518855506008007, PUR: 0.3625.  Name: %r.


 Time: 63.56625270843506
INFO - hyperopt - Result: {'NMI': 0.03460001109980916, 'Purity': 0.3625, 'AMI': -0.014518855506008007, 'Silhouette Score': -0.13116605354887978, 'Calinski-Harabasz Index': 0.7873223885308509, 'Davies-Bouldin Index': 2.2967768395046306}
INFO - hyperopt - Completed after 0:01:04
