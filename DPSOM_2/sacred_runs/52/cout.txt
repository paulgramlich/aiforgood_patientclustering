INFO - hyperopt - Running command 'main'
INFO - hyperopt - Started run with ID "52"
using LBP
num_features: 358
data_train_padded.shape: (928, 784)
data_train.shape: (394, 28, 28, 1), data_val.shape: (70, 28, 28, 1), data_test.shape: (464, 28, 28, 1)
Initializing global variables...
2024-06-26 12:06:07.705906: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled
Variables initialized.

**********Starting job hyperopt_100_2-2_2024-06-26_eaf32********* 

  0%|          | 0/155 [00:00<?, ?it/s]Number of batches: 1


Autoencoder Pretraining...

Starting epoch 1/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 561.5324096679688
Running validation...
Epoch 1, Step 0: Train Loss = 1725.588623046875, Test Loss = 1772.6121826171875
  1%|          | 1/155 [00:00<01:04,  2.40it/s, epoch=0, test_loss=1.77e+3, train_loss=1.73e+3]Starting epoch 2/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 1730.322021484375
Running validation...
Epoch 2, Step 0: Train Loss = 71914.5234375, Test Loss = 74678.109375
  1%|▏         | 2/155 [00:00<00:37,  4.06it/s, epoch=1, test_loss=7.47e+4, train_loss=7.19e+4]Starting epoch 3/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 71960.1796875
Running validation...
Epoch 3, Step 0: Train Loss = 898980.875, Test Loss = 933940.375
  2%|▏         | 3/155 [00:00<00:29,  5.21it/s, epoch=2, test_loss=9.34e+5, train_loss=8.99e+5]Starting epoch 4/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 901347.125
Running validation...
Epoch 4, Step 0: Train Loss = 13747.810546875, Test Loss = 13697.94140625
  3%|▎         | 4/155 [00:00<00:25,  5.97it/s, epoch=3, test_loss=1.37e+4, train_loss=1.37e+4]Starting epoch 5/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 13479.6328125
Running validation...
Epoch 5, Step 0: Train Loss = 17740.599609375, Test Loss = 18458.3828125
  3%|▎         | 5/155 [00:00<00:23,  6.51it/s, epoch=4, test_loss=1.85e+4, train_loss=17740.6]Starting epoch 6/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 17685.51171875
Running validation...
Epoch 6, Step 0: Train Loss = 152182.015625, Test Loss = 159484.140625
  4%|▍         | 6/155 [00:01<00:22,  6.75it/s, epoch=5, test_loss=1.59e+5, train_loss=1.52e+5]Starting epoch 7/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 151979.84375
Running validation...
Epoch 7, Step 0: Train Loss = 153173.5, Test Loss = 158079.078125
  5%|▍         | 7/155 [00:01<00:20,  7.06it/s, epoch=6, test_loss=1.58e+5, train_loss=1.53e+5]Starting epoch 8/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 150835.890625
Running validation...
Epoch 8, Step 0: Train Loss = 19759.419921875, Test Loss = 20134.48046875
  5%|▌         | 8/155 [00:01<00:20,  7.05it/s, epoch=7, test_loss=2.01e+4, train_loss=1.98e+4]Starting epoch 9/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 19343.69140625
Running validation...
Epoch 9, Step 0: Train Loss = 61780.70703125, Test Loss = 63806.92578125
  6%|▌         | 9/155 [00:01<00:20,  7.28it/s, epoch=8, test_loss=6.38e+4, train_loss=6.18e+4]Starting epoch 10/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 61824.33984375
Running validation...
Epoch 10, Step 0: Train Loss = 29136.99609375, Test Loss = 28826.95703125
  6%|▋         | 10/155 [00:01<00:20,  7.24it/s, epoch=9, test_loss=2.88e+4, train_loss=2.91e+4]Starting epoch 11/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 28632.06640625
Running validation...
Epoch 11, Step 0: Train Loss = 29451.9296875, Test Loss = 31468.8671875
  7%|▋         | 11/155 [00:01<00:19,  7.28it/s, epoch=10, test_loss=3.15e+4, train_loss=2.95e+4]Starting epoch 12/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 30642.001953125
Running validation...
Epoch 12, Step 0: Train Loss = 16408.658203125, Test Loss = 16231.462890625
  8%|▊         | 12/155 [00:01<00:19,  7.52it/s, epoch=11, test_loss=1.62e+4, train_loss=1.64e+4]Starting epoch 13/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 15846.6669921875
Running validation...
Epoch 13, Step 0: Train Loss = 26234.51953125, Test Loss = 27341.5390625
  8%|▊         | 13/155 [00:01<00:18,  7.48it/s, epoch=12, test_loss=2.73e+4, train_loss=2.62e+4]Starting epoch 14/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 26307.501953125
Running validation...
Epoch 14, Step 0: Train Loss = 36782.21875, Test Loss = 38545.203125
  9%|▉         | 14/155 [00:02<00:18,  7.48it/s, epoch=13, test_loss=3.85e+4, train_loss=3.68e+4]Starting epoch 15/15
Batch 1/1
Batch data shape: (300, 28, 28, 1)
Train Loss: 36636.21875
Running validation...
Epoch 15, Step 0: Train Loss = 10490.66796875, Test Loss = 9887.8271484375
 10%|▉         | 15/155 [00:02<00:18,  7.46it/s, epoch=14, test_loss=9.89e+3, train_loss=1.05e+4]

SOM initialization...

 22%|██▏       | 34/155 [00:03<00:08, 13.74it/s, epoch=3, test_loss=312, train_loss=307]         

Training...

 23%|██▎       | 36/155 [00:04<00:19,  6.23it/s, cah=[-1.2417553e-07], cr_ratio=2.55e+4, cs_ratio=-8.96e-8, epoch=0, ssom=[1.3862946], test_loss=3.66e+4, train_loss=3.5e+4, vae=[35380.02], vc_ratio=-2.85e+11]/Users/paulgramlich/Developer/git/aiforgood_patientclustering/dpsom/dpsom/DPSOM.py:410: RuntimeWarning: divide by zero encountered in scalar divide
  vae_cah_ratio=elbo_loss[0]/cah_loss[0]
 29%|██▉       | 45/155 [00:09<00:52,  2.10it/s, cah=[3.576278e-08], cr_ratio=1.3e+4, cs_ratio=6.45e-9, epoch=9, ssom=[1.3862946], test_loss=7.1e+3, train_loss=7.21e+3, vae=[7083.7266], vc_ratio=inf]         
INFO:tensorflow:Restoring parameters from ../models/hyperopt_100_2-2_2024-06-26_eaf32/hyperopt_100_2-2_2024-06-26_eaf32.ckpt
INFO - tensorflow - Restoring parameters from ../models/hyperopt_100_2-2_2024-06-26_eaf32/hyperopt_100_2-2_2024-06-26_eaf32.ckpt
Evaluation...
 87%|████████▋ | 135/155 [00:56<00:08,  2.38it/s, cah=[1.7069632e-07], cr_ratio=2.08e+3, cs_ratio=9.65e-8, epoch=99, ssom=[1.3862946], test_loss=162, train_loss=151, vae=[149.81558], vc_ratio=inf]

 NMI: 0.010951636054591997, AMI: -0.006876791714221179, PUR: 0.35.  Name: %r.


 Time: 57.53536581993103
INFO - hyperopt - Result: {'NMI': 0.010951636054591997, 'Purity': 0.35, 'AMI': -0.006876791714221179}
INFO - hyperopt - Completed after 0:00:58
